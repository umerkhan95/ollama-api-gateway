{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EdgeLLM INT8 Tensor Core Benchmark\n",
    "\n",
    "This notebook benchmarks the INT8 Tensor Core implementation for EdgeLLM on Tesla T4 GPU.\n",
    "\n",
    "**Tests:**\n",
    "1. GPU hardware detection and Tensor Core capability\n",
    "2. Kernel compilation with WMMA support\n",
    "3. Weight expansion (2-bit to INT8)\n",
    "4. Activation quantization (FP32 to INT8)\n",
    "5. INT8 Tensor Core matmul performance\n",
    "6. Comparison: Phase 2.1 vs INT8 TC\n",
    "7. Precision validation\n",
    "\n",
    "**Target:** 1000+ tok/s (vs 630 tok/s Phase 2.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Check GPU\n",
    "result = subprocess.run(['nvidia-smi', '--query-gpu=name,compute_cap,memory.total,driver_version', \n",
    "                         '--format=csv,noheader'], capture_output=True, text=True)\n",
    "gpu_info = result.stdout.strip()\n",
    "print(f\"GPU: {gpu_info}\")\n",
    "\n",
    "# Parse GPU info\n",
    "parts = gpu_info.split(', ')\n",
    "GPU_NAME = parts[0] if len(parts) > 0 else 'Unknown'\n",
    "COMPUTE_CAP = parts[1] if len(parts) > 1 else '0.0'\n",
    "VRAM_MB = int(parts[2].replace(' MiB', '')) if len(parts) > 2 else 0\n",
    "\n",
    "# Check if INT8 Tensor Cores are available (compute 7.5+)\n",
    "cc_major, cc_minor = map(int, COMPUTE_CAP.split('.'))\n",
    "cc_int = cc_major * 10 + cc_minor\n",
    "HAS_INT8_TC = cc_int >= 75\n",
    "\n",
    "print(f\"\\nCompute Capability: {COMPUTE_CAP} (cc={cc_int})\")\n",
    "print(f\"INT8 Tensor Cores: {'Available' if HAS_INT8_TC else 'NOT AVAILABLE'}\")\n",
    "print(f\"VRAM: {VRAM_MB} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!rm -rf ollama-api-gateway\n",
    "!git clone --depth 1 https://github.com/umerkhan95/ollama-api-gateway.git\n",
    "%cd ollama-api-gateway/mojo-gateway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build CUDA Kernels with Tensor Core Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CUDA version\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build with T4 Tensor Core support\n",
    "%cd src/kernels/cuda\n",
    "!make clean\n",
    "!make t4\n",
    "print(\"\\nBuild complete!\")\n",
    "!ls -la ../../../lib/*.so 2>/dev/null || echo \"Library not found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Test Harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test_int8_tc.cu\n",
    "/**\n",
    " * INT8 Tensor Core Benchmark Test\n",
    " * Tests weight expansion, activation quantization, and TC matmul\n",
    " */\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "#include <math.h>\n",
    "#include <cuda_runtime.h>\n",
    "#include <chrono>\n",
    "#include \"tmac_kernel_cuda.h\"\n",
    "\n",
    "#define WARMUP_RUNS 10\n",
    "#define BENCHMARK_RUNS 100\n",
    "\n",
    "// Test configurations matching SmolLM-135M layers\n",
    "struct LayerConfig {\n",
    "    const char* name;\n",
    "    int M;  // Output rows\n",
    "    int K;  // Inner dimension\n",
    "};\n",
    "\n",
    "LayerConfig LAYERS[] = {\n",
    "    {\"QKV Projection\", 1728, 576},\n",
    "    {\"Output Projection\", 576, 576},\n",
    "    {\"FFN Up\", 1536, 576},\n",
    "    {\"FFN Down\", 576, 1536},\n",
    "    {\"Large Test\", 4096, 4096},\n",
    "};\n",
    "const int NUM_LAYERS = sizeof(LAYERS) / sizeof(LAYERS[0]);\n",
    "\n",
    "// Generate random ternary weights\n",
    "void generate_ternary_weights(int8_t* packed, float* scales, int M, int K) {\n",
    "    int packed_size = M * ((K + 3) / 4);\n",
    "    for (int i = 0; i < packed_size; i++) {\n",
    "        // Pack 4 ternary values (0,1,2 -> -1,0,+1)\n",
    "        packed[i] = (rand() % 3) | ((rand() % 3) << 2) | \n",
    "                    ((rand() % 3) << 4) | ((rand() % 3) << 6);\n",
    "    }\n",
    "    for (int i = 0; i < M; i++) {\n",
    "        scales[i] = 0.1f + (rand() / (float)RAND_MAX) * 0.1f;\n",
    "    }\n",
    "}\n",
    "\n",
    "// Generate random activations\n",
    "void generate_activations(float* act, int K) {\n",
    "    for (int i = 0; i < K; i++) {\n",
    "        act[i] = -1.0f + 2.0f * (rand() / (float)RAND_MAX);\n",
    "    }\n",
    "}\n",
    "\n",
    "// Benchmark a kernel\n",
    "double benchmark_kernel(const char* name, int (*kernel_fn)(const float*, float*, int, int, int),\n",
    "                        float* activations, float* output, int M, int N, int K) {\n",
    "    // Warmup\n",
    "    for (int i = 0; i < WARMUP_RUNS; i++) {\n",
    "        kernel_fn(activations, output, M, N, K);\n",
    "    }\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Benchmark\n",
    "    auto start = std::chrono::high_resolution_clock::now();\n",
    "    for (int i = 0; i < BENCHMARK_RUNS; i++) {\n",
    "        kernel_fn(activations, output, M, N, K);\n",
    "    }\n",
    "    cudaDeviceSynchronize();\n",
    "    auto end = std::chrono::high_resolution_clock::now();\n",
    "    \n",
    "    double total_ms = std::chrono::duration<double, std::milli>(end - start).count();\n",
    "    return total_ms / BENCHMARK_RUNS;\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"\\n\" \"=\" \"=\"*78 \"\\n\");\n",
    "    printf(\"EdgeLLM INT8 Tensor Core Benchmark\\n\");\n",
    "    printf(\"=\" \"=\"*78 \"\\n\\n\");\n",
    "    \n",
    "    // Get device info\n",
    "    int cc = cuda_get_compute_capability();\n",
    "    int has_tc = cuda_has_int8_tensorcore();\n",
    "    int num_gpus = cuda_get_device_count();\n",
    "    \n",
    "    printf(\"Device Info:\\n\");\n",
    "    printf(\"  GPU: %s\\n\", cuda_device_name());\n",
    "    printf(\"  Compute Capability: %d.%d (cc=%d)\\n\", cc/10, cc%10, cc);\n",
    "    printf(\"  INT8 Tensor Cores: %s\\n\", has_tc ? \"YES\" : \"NO\");\n",
    "    printf(\"  Number of GPUs: %d\\n\\n\", num_gpus);\n",
    "    \n",
    "    // Initialize CUDA\n",
    "    int max_M = 4096;\n",
    "    int max_K = 4096;\n",
    "    int max_weights = max_M * ((max_K + 3) / 4);\n",
    "    \n",
    "    if (cuda_init(max_weights, max_K, max_M) != 0) {\n",
    "        fprintf(stderr, \"Failed to initialize CUDA\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    // Allocate buffers\n",
    "    int8_t* packed_weights = (int8_t*)malloc(max_weights);\n",
    "    float* scales = (float*)malloc(max_M * sizeof(float));\n",
    "    float* activations = (float*)malloc(max_K * sizeof(float));\n",
    "    float* output_phase21 = (float*)malloc(max_M * sizeof(float));\n",
    "    float* output_int8tc = (float*)malloc(max_M * sizeof(float));\n",
    "    float* norm_weights = (float*)malloc(max_K * sizeof(float));\n",
    "    \n",
    "    // Initialize norm weights\n",
    "    for (int i = 0; i < max_K; i++) {\n",
    "        norm_weights[i] = 0.9f + 0.2f * (rand() / (float)RAND_MAX);\n",
    "    }\n",
    "    \n",
    "    printf(\"\\n\" \"-\" \"-\"*78 \"\\n\");\n",
    "    printf(\"KERNEL BENCHMARK RESULTS\\n\");\n",
    "    printf(\"-\" \"-\"*78 \"\\n\\n\");\n",
    "    \n",
    "    printf(\"| %-20s | %8s | %8s | %8s | %8s | %8s |\\n\",\n",
    "           \"Layer\", \"M\", \"K\", \"Phase2.1\", \"INT8 TC\", \"Speedup\");\n",
    "    printf(\"|\" \"-\" \"-\"*21 \"|\" \"-\" \"-\"*9 \"|\" \"-\" \"-\"*9 \"|\" \"-\" \"-\"*9 \"|\" \"-\" \"-\"*9 \"|\" \"-\" \"-\"*9 \"|\\n\");\n",
    "    \n",
    "    double total_phase21 = 0;\n",
    "    double total_int8tc = 0;\n",
    "    \n",
    "    for (int layer = 0; layer < NUM_LAYERS; layer++) {\n",
    "        int M = LAYERS[layer].M;\n",
    "        int K = LAYERS[layer].K;\n",
    "        int N = 1;  // batch size = 1\n",
    "        int weight_bytes = M * ((K + 3) / 4);\n",
    "        \n",
    "        // Generate test data\n",
    "        generate_ternary_weights(packed_weights, scales, M, K);\n",
    "        generate_activations(activations, K);\n",
    "        \n",
    "        // Load weights for Phase 2.1 (persistent)\n",
    "        cuda_load_weights(packed_weights, scales, weight_bytes, M);\n",
    "        cuda_load_norm_weights(norm_weights, K);\n",
    "        \n",
    "        // Benchmark Phase 2.1 (streaming fused)\n",
    "        double ms_phase21 = benchmark_kernel(\"Phase2.1\",\n",
    "            [](const float* act, float* out, int m, int n, int k) -> int {\n",
    "                return streaming_fused_rmsnorm_matmul_cuda(act, out, m, k, 1e-5f);\n",
    "            },\n",
    "            activations, output_phase21, M, N, K);\n",
    "        \n",
    "        // Load weights for INT8 TC\n",
    "        cuda_load_weights_int8_tc(packed_weights, scales, weight_bytes, M, K);\n",
    "        \n",
    "        // Benchmark INT8 TC\n",
    "        double ms_int8tc = benchmark_kernel(\"INT8 TC\",\n",
    "            [](const float* act, float* out, int m, int n, int k) -> int {\n",
    "                return streaming_fused_rmsnorm_matmul_int8_tc(act, out, m, k, 1e-5f);\n",
    "            },\n",
    "            activations, output_int8tc, M, N, K);\n",
    "        \n",
    "        double speedup = ms_phase21 / ms_int8tc;\n",
    "        total_phase21 += ms_phase21;\n",
    "        total_int8tc += ms_int8tc;\n",
    "        \n",
    "        printf(\"| %-20s | %8d | %8d | %7.3fms | %7.3fms | %7.2fx |\\n\",\n",
    "               LAYERS[layer].name, M, K, ms_phase21, ms_int8tc, speedup);\n",
    "        \n",
    "        // Precision validation\n",
    "        float max_error = 0;\n",
    "        float mean_error = 0;\n",
    "        for (int i = 0; i < M; i++) {\n",
    "            float err = fabsf(output_phase21[i] - output_int8tc[i]);\n",
    "            float rel_err = err / (fabsf(output_phase21[i]) + 1e-6f);\n",
    "            max_error = fmaxf(max_error, rel_err);\n",
    "            mean_error += rel_err;\n",
    "        }\n",
    "        mean_error /= M;\n",
    "        \n",
    "        if (max_error > 0.02f) {\n",
    "            printf(\"  WARNING: Precision issue! Max error: %.4f, Mean: %.6f\\n\", max_error, mean_error);\n",
    "        }\n",
    "        \n",
    "        cuda_unload_weights_int8_tc();\n",
    "        cuda_unload_weights();\n",
    "    }\n",
    "    \n",
    "    printf(\"|\" \"-\" \"-\"*21 \"|\" \"-\" \"-\"*9 \"|\" \"-\" \"-\"*9 \"|\" \"-\" \"-\"*9 \"|\" \"-\" \"-\"*9 \"|\" \"-\" \"-\"*9 \"|\\n\");\n",
    "    printf(\"| %-20s | %8s | %8s | %7.3fms | %7.3fms | %7.2fx |\\n\",\n",
    "           \"TOTAL\", \"\", \"\", total_phase21, total_int8tc, total_phase21/total_int8tc);\n",
    "    \n",
    "    // Calculate throughput\n",
    "    printf(\"\\n\" \"-\" \"-\"*78 \"\\n\");\n",
    "    printf(\"THROUGHPUT ESTIMATE\\n\");\n",
    "    printf(\"-\" \"-\"*78 \"\\n\\n\");\n",
    "    \n",
    "    // SmolLM-135M has 9 layers, each layer = QKV + Out + FFN_up + FFN_down\n",
    "    double total_layer_ms = 0;\n",
    "    for (int i = 0; i < 4; i++) {  // First 4 layers represent one transformer layer\n",
    "        int M = LAYERS[i].M;\n",
    "        int K = LAYERS[i].K;\n",
    "        int weight_bytes = M * ((K + 3) / 4);\n",
    "        \n",
    "        generate_ternary_weights(packed_weights, scales, M, K);\n",
    "        generate_activations(activations, K);\n",
    "        cuda_load_weights_int8_tc(packed_weights, scales, weight_bytes, M, K);\n",
    "        cuda_load_norm_weights(norm_weights, K);\n",
    "        \n",
    "        double ms = benchmark_kernel(\"INT8 TC\",\n",
    "            [](const float* act, float* out, int m, int n, int k) -> int {\n",
    "                return streaming_fused_rmsnorm_matmul_int8_tc(act, out, m, k, 1e-5f);\n",
    "            },\n",
    "            activations, output_int8tc, M, 1, K);\n",
    "        total_layer_ms += ms;\n",
    "        \n",
    "        cuda_unload_weights_int8_tc();\n",
    "    }\n",
    "    \n",
    "    double per_token_ms = total_layer_ms * 9;  // 9 transformer layers\n",
    "    double tokens_per_sec = 1000.0 / per_token_ms;\n",
    "    \n",
    "    printf(\"Per-layer latency (INT8 TC): %.3f ms\\n\", total_layer_ms);\n",
    "    printf(\"Per-token latency (9 layers): %.3f ms\\n\", per_token_ms);\n",
    "    printf(\"Estimated throughput: %.1f tok/s\\n\", tokens_per_sec);\n",
    "    printf(\"\\nPhase 2.1 baseline: 630 tok/s\\n\");\n",
    "    printf(\"Speedup vs Phase 2.1: %.2fx\\n\", tokens_per_sec / 630.0);\n",
    "    printf(\"\\nOllama baseline: 423 tok/s\\n\");\n",
    "    printf(\"Speedup vs Ollama: %.2fx\\n\", tokens_per_sec / 423.0);\n",
    "    \n",
    "    // Output JSON results\n",
    "    printf(\"\\n\" \"-\" \"-\"*78 \"\\n\");\n",
    "    printf(\"JSON OUTPUT\\n\");\n",
    "    printf(\"-\" \"-\"*78 \"\\n\\n\");\n",
    "    \n",
    "    printf(\"{\\n\");\n",
    "    printf(\"  \\\"gpu\\\": \\\"%s\\\",\\n\", cuda_device_name());\n",
    "    printf(\"  \\\"compute_capability\\\": %d,\\n\", cc);\n",
    "    printf(\"  \\\"has_int8_tensorcore\\\": %s,\\n\", has_tc ? \"true\" : \"false\");\n",
    "    printf(\"  \\\"per_token_ms\\\": %.4f,\\n\", per_token_ms);\n",
    "    printf(\"  \\\"throughput_tok_s\\\": %.2f,\\n\", tokens_per_sec);\n",
    "    printf(\"  \\\"speedup_vs_phase21\\\": %.2f,\\n\", tokens_per_sec / 630.0);\n",
    "    printf(\"  \\\"speedup_vs_ollama\\\": %.2f\\n\", tokens_per_sec / 423.0);\n",
    "    printf(\"}\\n\");\n",
    "    \n",
    "    // Cleanup\n",
    "    free(packed_weights);\n",
    "    free(scales);\n",
    "    free(activations);\n",
    "    free(output_phase21);\n",
    "    free(output_int8tc);\n",
    "    free(norm_weights);\n",
    "    cuda_cleanup();\n",
    "    \n",
    "    printf(\"\\nBenchmark complete!\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and run benchmark\n",
    "!nvcc -O3 -gencode arch=compute_75,code=sm_75 --expt-relaxed-constexpr \\\n",
    "    -o test_int8_tc test_int8_tc.cu tmac_kernel.cu -lcudart\n",
    "print(\"Compilation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run benchmark\n",
    "!./test_int8_tc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Precision Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test_precision.cu\n",
    "/**\n",
    " * INT8 TC Precision Validation\n",
    " * Compares FP32 reference vs INT8 Tensor Core output\n",
    " */\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include \"tmac_kernel_cuda.h\"\n",
    "\n",
    "int main() {\n",
    "    printf(\"INT8 Tensor Core Precision Validation\\n\");\n",
    "    printf(\"=\"*50 \"\\n\\n\");\n",
    "    \n",
    "    // Test sizes\n",
    "    int test_sizes[][2] = {\n",
    "        {576, 576},\n",
    "        {1728, 576},\n",
    "        {1536, 576},\n",
    "        {576, 1536},\n",
    "    };\n",
    "    int num_tests = 4;\n",
    "    \n",
    "    cuda_init(1024*1024, 4096, 4096);\n",
    "    \n",
    "    for (int t = 0; t < num_tests; t++) {\n",
    "        int M = test_sizes[t][0];\n",
    "        int K = test_sizes[t][1];\n",
    "        int weight_bytes = M * ((K + 3) / 4);\n",
    "        \n",
    "        // Allocate\n",
    "        int8_t* weights = (int8_t*)malloc(weight_bytes);\n",
    "        float* scales = (float*)malloc(M * sizeof(float));\n",
    "        float* activations = (float*)malloc(K * sizeof(float));\n",
    "        float* norm_weights = (float*)malloc(K * sizeof(float));\n",
    "        float* output_fp32 = (float*)malloc(M * sizeof(float));\n",
    "        float* output_int8 = (float*)malloc(M * sizeof(float));\n",
    "        \n",
    "        // Initialize\n",
    "        srand(42);  // Reproducible\n",
    "        for (int i = 0; i < weight_bytes; i++) {\n",
    "            weights[i] = rand() & 0xFF;\n",
    "        }\n",
    "        for (int i = 0; i < M; i++) {\n",
    "            scales[i] = 0.1f + 0.1f * (rand() / (float)RAND_MAX);\n",
    "        }\n",
    "        for (int i = 0; i < K; i++) {\n",
    "            activations[i] = -1.0f + 2.0f * (rand() / (float)RAND_MAX);\n",
    "            norm_weights[i] = 0.9f + 0.2f * (rand() / (float)RAND_MAX);\n",
    "        }\n",
    "        \n",
    "        // FP32 reference (Phase 2.1)\n",
    "        cuda_load_weights(weights, scales, weight_bytes, M);\n",
    "        cuda_load_norm_weights(norm_weights, K);\n",
    "        streaming_fused_rmsnorm_matmul_cuda(activations, output_fp32, M, K, 1e-5f);\n",
    "        cuda_unload_weights();\n",
    "        \n",
    "        // INT8 TC\n",
    "        cuda_load_weights_int8_tc(weights, scales, weight_bytes, M, K);\n",
    "        cuda_load_norm_weights(norm_weights, K);\n",
    "        streaming_fused_rmsnorm_matmul_int8_tc(activations, output_int8, M, K, 1e-5f);\n",
    "        cuda_unload_weights_int8_tc();\n",
    "        \n",
    "        // Compare\n",
    "        float max_abs_err = 0;\n",
    "        float max_rel_err = 0;\n",
    "        float sum_rel_err = 0;\n",
    "        int num_large_errors = 0;\n",
    "        \n",
    "        for (int i = 0; i < M; i++) {\n",
    "            float abs_err = fabsf(output_fp32[i] - output_int8[i]);\n",
    "            float rel_err = abs_err / (fabsf(output_fp32[i]) + 1e-6f);\n",
    "            \n",
    "            max_abs_err = fmaxf(max_abs_err, abs_err);\n",
    "            max_rel_err = fmaxf(max_rel_err, rel_err);\n",
    "            sum_rel_err += rel_err;\n",
    "            \n",
    "            if (rel_err > 0.01f) num_large_errors++;\n",
    "        }\n",
    "        float mean_rel_err = sum_rel_err / M;\n",
    "        \n",
    "        printf(\"Test %d: M=%d, K=%d\\n\", t+1, M, K);\n",
    "        printf(\"  Max absolute error: %.6f\\n\", max_abs_err);\n",
    "        printf(\"  Max relative error: %.4f (%.2f%%)\\n\", max_rel_err, max_rel_err*100);\n",
    "        printf(\"  Mean relative error: %.6f (%.4f%%)\\n\", mean_rel_err, mean_rel_err*100);\n",
    "        printf(\"  Errors > 1%%: %d / %d (%.2f%%)\\n\", num_large_errors, M, 100.0f*num_large_errors/M);\n",
    "        printf(\"  Status: %s\\n\\n\", max_rel_err < 0.02f ? \"PASS\" : \"FAIL\");\n",
    "        \n",
    "        free(weights);\n",
    "        free(scales);\n",
    "        free(activations);\n",
    "        free(norm_weights);\n",
    "        free(output_fp32);\n",
    "        free(output_int8);\n",
    "    }\n",
    "    \n",
    "    cuda_cleanup();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -O3 -gencode arch=compute_75,code=sm_75 --expt-relaxed-constexpr \\\n",
    "    -o test_precision test_precision.cu tmac_kernel.cu -lcudart\n",
    "!./test_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create summary report\n",
    "report = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"gpu\": GPU_NAME,\n",
    "    \"compute_capability\": COMPUTE_CAP,\n",
    "    \"vram_mb\": VRAM_MB,\n",
    "    \"has_int8_tensorcore\": HAS_INT8_TC,\n",
    "    \"benchmark\": \"INT8 Tensor Core vs Phase 2.1\",\n",
    "    \"target_throughput\": \"1000+ tok/s\",\n",
    "    \"baseline_phase21\": \"630 tok/s\",\n",
    "    \"baseline_ollama\": \"423 tok/s\",\n",
    "}\n",
    "\n",
    "print(json.dumps(report, indent=2))\n",
    "\n",
    "# Save report\n",
    "with open('int8_tc_benchmark_report.json', 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "print(\"\\nReport saved to int8_tc_benchmark_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup test files\n",
    "!rm -f test_int8_tc test_precision test_int8_tc.cu test_precision.cu\n",
    "print(\"Cleanup complete!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
